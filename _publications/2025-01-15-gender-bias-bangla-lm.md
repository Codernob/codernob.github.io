---
title: "Assessing Gender Bias of Pretrained Bangla Language Models in STEM and SHAPE Fields"
collection: publications
category: conferences
permalink: /publication/2025-06-01-gender-bias-bangla-lm
excerpt: 'Evaluated gender bias of 11 pretrained Bangla large and small language models using 5 numerical and visual metrics across STEM and SHAPE professional fields.'
date: 2025-06-01
venue: '6th Workshop on Gender Bias in Natural Language Processing (GeBNLP) at ACL 2025'
paperurl: 'https://aclanthology.org/2025.gebnlp-1.24/'
---

This work evaluated gender bias in 11 pretrained Bangla language models using diverse numerical and visual metrics. 

<img width="1072" height="438" alt="image" src="https://github.com/user-attachments/assets/bda629c9-356b-482d-ba04-81f126bdfa50" />


**Key Contributions:**
- Developed a diverse dataset containing words representing Male, Female, STEM, and SHAPE (Social Sciences Humanities and the Arts for People and the Economy) categories
- Evaluated gender bias using 5 numerical and visual metrics
- Identified the out-of-vocabulary issue as an obstacle in effective bias detection
- Revealed how training language models using unfiltered data can lead to bias in pretrained models
- Used t-SNE visualization and corpus analysis to investigate cases where statistically significant gender bias was not detected

This research highlights the importance of careful dataset curation and vocabulary coverage in bias evaluation for low-resource languages.

Read the paper [here](https://aclanthology.org/2025.gebnlp-1.24/)
[Implementation on GitHub](https://github.com/HerWILL-Inc/ACL-2025/)

**Recommended citation:**

```bibtex
@inproceedings{arnob2025assessing,
  title={Assessing Gender Bias of Pretrained Bangla Language Models in STEM and SHAPE Fields},
  author={Arnob, Noor Mairukh Khan and Mahmud, Saiyara and Wasi, Azmine Toushik},
  booktitle={Proceedings of the 6th Workshop on Gender Bias in Natural Language Processing (GeBNLP)},
  pages={268--281},
  year={2025}
}
```
