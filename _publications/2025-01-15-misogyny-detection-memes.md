---
title: "Ensemble approach for misogyny detection in memes using pre-trained text and vision transformers"
collection: publications
category: conferences
permalink: /publication/2025-05-01-misogyny-detection-memes
excerpt: 'Developed an ensemble approach using CLIP and Large Language Models for detecting misogyny in memes, achieving runner-up position in the DravidianLangTech@NAACL 2025 shared task.'
date: 2025-05-01
venue: 'Fifth Workshop on Speech, Vision, and Language Technologies for Dravidian Languages at NAACL 2025'
paperurl: 'https://aclanthology.org/2025.dravidianlangtech-1.63/'
---

This work developed a hate-aware multimodal approach for detecting misogyny in memes, achieving runner-up position in the shared task competition.

<img width="553" height="543" alt="image" src="https://github.com/user-attachments/assets/8712670e-9011-4712-b9e2-21839517eaf8" />


**Key Contributions:**
- Employed Large Language Models for extracting rich semantic information using text embeddings
- Used CLIP models for obtaining accurate image latents
- Trained an efficient MLP for detecting misogyny from combined image and text embeddings
- Demonstrated effective integration of vision transformers and text transformers for multimodal classification

This research addresses the important problem of detecting harmful content in memes, which require understanding both visual and textual components.

**Achievement:** Runner-up in the Misogyny Meme Detection Shared Task at DravidianLangTech@NAACL 2025

Read the paper [here](https://aclanthology.org/2025.dravidianlangtech-1.63/)
[Implementation on GitHub](https://github.com/HerWILL-Inc/NAACL-2025)

**Recommended citation:**

```bibtex
@inproceedings{preeti2025herwill,
  title={HerWILL@ DravidianLangTech 2025: Ensemble Approach for Misogyny Detection in Memes Using Pre-trained Text and Vision Transformers},
  author={Preeti, Neelima Monjusha and Chakraborty, Trina and Arnob, Noor Mairukh Khan and Mahmud, Saiyara and Wasi, Azmine Toushik},
  booktitle={Proceedings of the Fifth Workshop on Speech, Vision, and Language Technologies for Dravidian Languages},
  pages={355--360},
  year={2025}
}
```
