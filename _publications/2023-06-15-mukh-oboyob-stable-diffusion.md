---
title: "Mukh-Oboyob: Stable Diffusion and BanglaBERT Enhanced Bangla Text-to-Face Synthesis"
collection: publications
category: manuscripts
permalink: /publication/2023-11-01-mukh-oboyob-stable-diffusion
excerpt: 'Developed an improved Bangla text-to-face generation system using Stable Diffusion and BanglaBERT, funded by UAP research grant.'
date: 2023-11-01
venue: 'International Journal of Advanced Computer Science & Applications'
paperurl: 'https://thesai.org/Publications/ViewPaper?Volume=14&Issue=11&Code=IJACSA&SerialNo=142'
citation: 'Saha, A. K., Arnob, N. M. K., Rahman, N. N., Haque, M., Al Masud, S. M. R., & Rahman, R. (2023). Mukh-Oboyob: Stable Diffusion and BanglaBERT Enhanced Bangla Text-to-Face Synthesis. International Journal of Advanced Computer Science & Applications, 14(11).'
---

This work extends earlier text-to-face generation research by leveraging state-of-the-art generative models to produce more realistic and diverse facial images from Bangla text descriptions.

**Key Contributions:**
- Supported by a research project funded by the Institute of Energy, Environment, Research and Development (IEERD) at UAP
- Prepared the research proposal that secured a $3,000 grant
- Developed a system leveraging Stable Diffusion (less prone to mode collapse than GANs) for realistic image generation
- Integrated BanglaBERT (ELECTRA-based language model) for accurate Bangla text embeddings
- Significantly improved image quality compared to GAN-based approaches
- Contributed substantially to writing and publication process

This research demonstrates the effectiveness of diffusion models over GANs for text-to-image generation, particularly in addressing issues like mode collapse, unstable training, and non-convergence.

**Funding:** Institute of Energy, Environment, Research and Development (IEERD), University of Asia Pacific (~$3,000)

[Implementation on GitHub](https://github.com/Codernob/Mukh-Oboyob)
