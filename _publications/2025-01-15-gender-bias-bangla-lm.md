---
title: "Assessing Gender Bias of Pretrained Bangla Language Models in STEM and SHAPE Fields"
collection: publications
category: conferences
permalink: /publication/2025-06-01-gender-bias-bangla-lm
excerpt: 'Evaluated gender bias of 11 pretrained Bangla large and small language models using 5 numerical and visual metrics across STEM and SHAPE professional fields.'
date: 2025-06-01
venue: '6th Workshop on Gender Bias in Natural Language Processing (GeBNLP) at ACL 2025'
paperurl: 'https://github.com/your-implementation-link'
citation: 'Arnob, N. M. K., Mahmud, S., & Wasi, A. T. (2025). Assessing Gender Bias of Pretrained Bangla Language Models in STEM and SHAPE Fields. In Proceedings of the 6th Workshop on Gender Bias in Natural Language Processing (GeBNLP). ACL 2025.'
---

This work evaluated gender bias in 11 pretrained Bangla language models using diverse numerical and visual metrics. 

**Key Contributions:**
- Developed a diverse dataset containing words representing Male, Female, STEM, and SHAPE (Social Sciences Humanities and the Arts for People and the Economy) categories
- Evaluated gender bias using 5 numerical and visual metrics
- Identified the out-of-vocabulary issue as an obstacle in effective bias detection
- Revealed how training language models using unfiltered data can lead to bias in pretrained models
- Used t-SNE visualization and corpus analysis to investigate cases where statistically significant gender bias was not detected

This research highlights the importance of careful dataset curation and vocabulary coverage in bias evaluation for low-resource languages.

[Implementation on GitHub](https://github.com/HerWILL-Inc/ACL-2025/)
